{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk as nltk\n",
    "\n",
    "import re\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kandy/hdd/master-thesis/constituency-parsing/datasets/\n"
     ]
    }
   ],
   "source": [
    "dirname = os.getcwd()\n",
    "dirname = os.path.dirname(dirname)\n",
    "dataset_path = os.path.join(dirname, 'datasets/')\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the corpus and extract the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pierre &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; years old &lt;/s&gt; will join...</td>\n",
       "      <td>[[[(&lt;/s&gt; (&lt;/s&gt; pierre) (&lt;/s&gt; vinken)), (&lt;/s&gt; &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;/s&gt; &lt;/s&gt; is chairman &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; the ...</td>\n",
       "      <td>[[[(&lt;/s&gt; mr&lt;/s&gt;), (&lt;/s&gt; vinken)], [(&lt;/s&gt; is), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt; &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; years old &lt;/s&gt; former chai...</td>\n",
       "      <td>[[[(&lt;/s&gt; (&lt;/s&gt; rudolph) (&lt;/s&gt; agnew)), (&lt;/s&gt; &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/s&gt; form &lt;/s&gt; asbestos once used * * &lt;/s&gt; mak...</td>\n",
       "      <td>[[[(&lt;/s&gt;\\n  (&lt;/s&gt;\\n    (&lt;/s&gt; (&lt;/s&gt; a) (&lt;/s&gt; fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the asbestos fiber &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; is unusually...</td>\n",
       "      <td>[[[(&lt;/s&gt;\\n  (&lt;/s&gt; (&lt;/s&gt; the) (&lt;/s&gt; asbestos) (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  pierre </s> </s> </s> years old </s> will join...   \n",
       "1  </s> </s> is chairman </s> </s> </s> </s> the ...   \n",
       "2  </s> </s> </s> </s> years old </s> former chai...   \n",
       "3  </s> form </s> asbestos once used * * </s> mak...   \n",
       "4  the asbestos fiber </s> </s> </s> is unusually...   \n",
       "\n",
       "                                                tree  \n",
       "0  [[[(</s> (</s> pierre) (</s> vinken)), (</s> <...  \n",
       "1  [[[(</s> mr</s>), (</s> vinken)], [(</s> is), ...  \n",
       "2  [[[(</s> (</s> rudolph) (</s> agnew)), (</s> <...  \n",
       "3  [[[(</s>\\n  (</s>\\n    (</s> (</s> a) (</s> fo...  \n",
       "4  [[[(</s>\\n  (</s> (</s> the) (</s> asbestos) (...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_treeData = pd.read_csv(dataset_path+'constituency-parsing-data-all-UNK.csv', sep=' ', header=None, )\n",
    "load_treeData.columns =['sentence', 'tree']\n",
    "load_treeData['tree'] = load_treeData['tree'].apply(nltk.Tree.fromstring)\n",
    "\n",
    "load_treeData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45162\n"
     ]
    }
   ],
   "source": [
    "trees = load_treeData['tree'].values.tolist()\n",
    "word_tokens = set()\n",
    "for tree in trees:\n",
    "    for word in tree.leaves():\n",
    "        word_tokens.add(word)\n",
    "        #word_tokens.add(word.lower()) # lower casing resulted in 44377 word tokens\n",
    "print(len(word_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Google word2vec vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965716\n"
     ]
    }
   ],
   "source": [
    "#googleVocab = pd.read_csv(dataset_path+'google-vocab.txt', sep=' ', header=None)\n",
    "#googleVocab.columns = ['word', 'index']\n",
    "#googleVocab.head()\n",
    "\n",
    "outfile = dataset_path +'google_word_corpus.pic'\n",
    "\n",
    "with open(outfile, 'rb') as pickle_file:    \n",
    "    googleCorpus, google_corpus_word_to_int, google_corpus_int_to_word = pickle.load(pickle_file)\n",
    "    \n",
    "google_vocab_set = set(googleCorpus)\n",
    "print(len(google_vocab_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearly 33% of words are missing. Casing does not make substantial difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15195\n",
      "33.64554271290022 % of words are missing!!!\n"
     ]
    }
   ],
   "source": [
    "diff_wj_google = word_tokens.difference(google_vocab_set)\n",
    "print(len(diff_wj_google))\n",
    "#print(diff_wj_google)\n",
    "print(float(len(diff_wj_google)) * 100 / float(len(word_tokens)), '% of words are missing!!!' )\n",
    "# lower casing resulted a difference of 13278 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783088\n"
     ]
    }
   ],
   "source": [
    "outfile = dataset_path +'glove_word_corpus.pic'\n",
    "\n",
    "with open(outfile, 'rb') as pickle_file:    \n",
    "    gloveCorpus, glove_corpus_word_to_int, glove_corpus_int_to_word = pickle.load(pickle_file)\n",
    "    \n",
    "gloveCorpus = set(gloveCorpus)\n",
    "print(len(gloveCorpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Glove nearly 90% of words are missing. Good to go with google word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39480\n",
      "87.4186262787299 % of words are missing!!!\n"
     ]
    }
   ],
   "source": [
    "diff_wj_glove = word_tokens.difference(gloveCorpus)\n",
    "print(len(diff_wj_glove))\n",
    "#print(diff_wj_google)\n",
    "print(float(len(diff_wj_glove)) * 100 / float(len(word_tokens)), '% of words are missing!!!' )\n",
    "# lower casing resulted a difference of 13278 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-master-thesis)",
   "language": "python",
   "name": "nlp-master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
